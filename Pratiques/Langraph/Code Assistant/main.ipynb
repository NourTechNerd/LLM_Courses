{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description :\n",
    "- Graph for Code Generation with Tests to validate the code generated , and we will provide Docs to help the LLM using RAG technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mThis is red text\u001b[0m\n",
      "\u001b[92mThis is green text\u001b[0m\n",
      "\u001b[93mThis is yellow text\u001b[0m\n",
      "\u001b[94mThis is blue text\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ANSI escape codes\n",
    "RED = \"\\033[91m\"\n",
    "GREEN = \"\\033[92m\"\n",
    "YELLOW = \"\\033[93m\"\n",
    "BLUE = \"\\033[94m\"\n",
    "RESET = \"\\033[0m\"\n",
    "\n",
    "print(f\"{RED}This is red text{RESET}\")\n",
    "print(f\"{GREEN}This is green text{RESET}\")\n",
    "print(f\"{YELLOW}This is yellow text{RESET}\")\n",
    "print(f\"{BLUE}This is blue text{RESET}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Tool :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Our Docs :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as Soup\n",
    "from langchain_community.document_loaders.recursive_url_loader import RecursiveUrlLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# LCEL docs \n",
    "# WebScraping of the WebPage about langchain Expressions language to counstruct our Doc\n",
    "\n",
    "url = \"https://python.langchain.com/v0.2/docs/concepts/#langchain-expression-language-lcel\"\n",
    "loader = RecursiveUrlLoader(\n",
    "    url=url, max_depth=20, extractor=lambda x: Soup(x, \"html.parser\").text\n",
    ")\n",
    "doc = loader.load()\n",
    "\n",
    "# Sort the list based on the URLs and get the text\n",
    "d_sorted = sorted(doc, key=lambda x: x.metadata[\"source\"])\n",
    "d_reversed = list(reversed(d_sorted))\n",
    "concatenated_content = \"\\n\\n\\n --- \\n\\n\\n\".join(\n",
    "    [doc.page_content for doc in d_reversed]\n",
    ")\n",
    "#print(\"🔋🔋🔋🔋🔋🔋🔋🔋🔋🔋🔋🔋🔋\")\n",
    "#print(doc[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################### Chunking\n",
    "def split_documents(documents):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=800,\n",
    "        chunk_overlap=80,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False,\n",
    "    )\n",
    "    return text_splitter.split_documents(documents)\n",
    "\n",
    "chunks = split_documents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings.ollama import OllamaEmbeddings\n",
    "\n",
    "def Embedding_function():\n",
    "    embeddings = OllamaEmbeddings(model=\"nomic-embed-text:v1.5\",show_progress =True)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Chroma DataBase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHROMA_PATH = \"/teamspace/studios/this_studio/LLM_Courses/Pratiques/Langraph/Code Assistant/Chroma\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_database():\n",
    "    if os.path.exists(CHROMA_PATH):\n",
    "        shutil.rmtree(CHROMA_PATH)\n",
    "        \n",
    "def save_to_chroma(chunks,Ids): \n",
    "    clear_database()\n",
    "    # Create a new DB from the chunks.\n",
    "    db = Chroma.from_documents(chunks, Embedding_function(), persist_directory=CHROMA_PATH,ids=Ids)\n",
    "    db.persist() # Forcing the Save\n",
    "    print(f\"Saved {len(chunks)} chunks to {CHROMA_PATH}.\")\n",
    "\n",
    "\n",
    "def Create_Chunks_Ids(chunks):\n",
    "    current_chunk_index = 0\n",
    "    ids = []\n",
    "    for chunk in chunks:\n",
    "        chunk.metadata[\"id\"] = f\"{current_chunk_index}\"\n",
    "        ids.append(f\"{current_chunk_index}\")\n",
    "        current_chunk_index+=1\n",
    "    return chunks,ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks,ids = Create_Chunks_Ids(chunks)\n",
    "chunks[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_chroma(chunks,ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching for relevent chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Context(Question):\n",
    "    # Searching for Relevent Chunks from DataBase\n",
    "    results = db.similarity_search_with_relevance_scores(Question,k=3)\n",
    "    context_text = \"\\n\\n---\\n\\n\".join([chunk.page_content for chunk, _score in results])\n",
    "    return context_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma(persist_directory=CHROMA_PATH, embedding_function=Embedding_function())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How can I use a prompt and model to create a chain in LCEL that returns raw ChatMessages?\"\n",
    "context = Get_Context(question)\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Graph :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START\n",
    "from langgraph.graph.message import add_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Node :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHROMA_PATH = \"/teamspace/studios/this_studio/LLM_Courses/Pratiques/Langraph/Code Assistant/Chroma\"\n",
    "db = Chroma(persist_directory=CHROMA_PATH, embedding_function=Embedding_function())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import StructuredTool\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class RAG_Arg(BaseModel):\n",
    "    query: str = Field(...,description=\"The query to use in searching for relevent information from  a the Database of information about LCEL\")\n",
    "\n",
    "def Get_Context(query:str)-> str:\n",
    "    # Searching for Relevent Chunks from DataBase\n",
    "    results = db.similarity_search_with_relevance_scores(query,k=3)\n",
    "    context_text = \"\\n\\n---\\n\\n\".join([chunk.page_content for chunk, _score in results])\n",
    "    return context_text\n",
    "\n",
    "RAG_System = StructuredTool.from_function(\n",
    "    func=Get_Context,\n",
    "    name=\"RAG System\",\n",
    "    description=\"This tool give a good informations about Langchain Expressions Launguage from the Documentation of Langchain Faramwork\",\n",
    "    args_schema=RAG_Arg,\n",
    "    return_direct=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "def Get_AIMessage(state:State):\n",
    "    messages = state.get(\"messages\", []) \n",
    "    # .get : Return the value associeted to the key \"messages\" if the key not exist it returns an empty list\n",
    "    if messages:\n",
    "        message = messages[-1]\n",
    "        # message is the last in messages list.\n",
    "    return message\n",
    "\n",
    "def RAG_function(state:State,tool = RAG_System):\n",
    "    message = Get_AIMessage(state)\n",
    "        \n",
    "    Tool_call = message.tool_calls[0]\n",
    "    print(\"Tofv ndnfvn    \",Tool_call.keys())\n",
    "    # Execute the Tool called by the LLM\n",
    "    Tool_arguments = Tool_call[\"args\"]\n",
    "    Tool_Name = Tool_call[\"name\"]\n",
    "    print(f\"⚙️{YELLOW} {Tool_Name} is Executing{RESET}\")\n",
    "    \n",
    "    Tool_result = tool.invoke(Tool_arguments)\n",
    "    Tool_Message =  ToolMessage(content=Tool_result,name=Tool_call[\"name\"],tool_call_id=Tool_call[\"id\"])\n",
    "    \n",
    "    return {\"messages\": Tool_Message}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Node :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [RAG_System]\n",
    "llm = ChatOpenAI(api_key=\"ollama\",model=\"llama3-groq-tool-use:8b\",base_url=\"http://localhost:11434/v1\")\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LLM_function(state: State):\n",
    "    #print(\"Sate :\",state)\n",
    "    #print(f\"State Messages : \",state[\"messages\"])\n",
    "    print(f\"{BLUE}State messages :{RESET}\",state[\"messages\"])\n",
    "    print(f\"💡{GREEN}LLM is Thinking !{RESET}\")\n",
    "    \n",
    "    prompt = state[\"messages\"] # List of Messages\n",
    "    response = llm_with_tools.invoke(prompt)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design The Graph :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_node(\"LLM\", LLM_function)\n",
    "graph_builder.add_node(\"RAG System\", RAG_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Condition_Function(state: State):\n",
    "    messages = state.get(\"messages\", [])\n",
    "    if messages : # check that messages is not an empty list\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"No messages found in State: {state}\")\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0: # Check if the LLM ask for a tool\n",
    "        \n",
    "        for tool_call in ai_message.tool_calls:\n",
    "            if tool_call['name'] == \"RAG System\":\n",
    "                return \"RAG System\"\n",
    "    return \"__end__\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_edge(START, \"LLM\")\n",
    "graph_builder.add_edge(\"RAG System\",\"LLM\")\n",
    "graph_builder.add_conditional_edges(\"LLM\",Condition_Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Graph :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interact with the Graph :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "How can I use a prompt and model to create a chain in LCEL that returns raw ChatMessages?, Give me the Code , The Prompt = Dogs aginst Chats, The Model is llama3 with Ollama server\n",
      "\u001b[94mState messages :\u001b[0m [SystemMessage(content='You are Code Assistent Bot have a strong Knowledge about Langchain exepression Language and you can use tools that can help you', id='f2303565-641f-4585-a472-60a53f06a893'), HumanMessage(content='hi!', id='2f301cc3-5d1b-4465-bf4b-e5c4a95af9bb'), AIMessage(content='Hello! How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 208, 'total_tokens': 218}, 'model_name': 'llama3-groq-tool-use:8b', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None}, id='run-12296008-71a5-46af-be54-eb5870d018c3-0', usage_metadata={'input_tokens': 208, 'output_tokens': 10, 'total_tokens': 218}), SystemMessage(content='You are Code Assistent Bot have a strong Knowledge about Langchain exepression Language and you can use tools that can help you', id='c9205bf3-6bff-4c7e-a132-7f5727a93cce'), HumanMessage(content='How can I use a prompt and model to create a chain in LCEL that returns raw ChatMessages?', id='ce42c607-750f-4b49-be75-b3e8689c8bc0'), AIMessage(content=\"To create a chain of prompts and models for generating raw Chat Messages using Langchain Expressions Language, you'll need to construct a query string. Could you provide me with the specifics of your prompt and desired output?\", response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 275, 'total_tokens': 319}, 'model_name': 'llama3-groq-tool-use:8b', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None}, id='run-e566ca92-7849-4d90-9d07-eafdc4f8f840-0', usage_metadata={'input_tokens': 275, 'output_tokens': 44, 'total_tokens': 319}), SystemMessage(content='You are Code Assistent Bot have a strong Knowledge about Langchain exepression Language and you can use tools that can help you', id='f696949a-bd55-4373-8beb-59825ffd7dfd'), HumanMessage(content='How can I use a prompt and model to create a chain in LCEL that returns raw ChatMessages?, Give me the Code', id='d5931ed2-6d1e-4080-99c5-3013a1bd12e9'), AIMessage(content=\"To assist you accurately, could you specify the exact prompt you wish to use and the model you'd like to leverage for generating these raw Chat Messages?\", response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 380, 'total_tokens': 411}, 'model_name': 'llama3-groq-tool-use:8b', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None}, id='run-c53c4a5d-73b5-4bf0-86f1-628397592d2c-0', usage_metadata={'input_tokens': 380, 'output_tokens': 31, 'total_tokens': 411}), SystemMessage(content='You are Code Assistent Bot have a strong Knowledge about Langchain exepression Language and you can use tools that can help you', id='7dfd83b5-76cf-41a3-98f3-b9cc7dd02e7b'), HumanMessage(content='How can I use a prompt and model to create a chain in LCEL that returns raw ChatMessages?, Give me the Code , The Prompt = Dogs aginst Chats, The Model is llama3 with Ollama server', id='d77997d8-449e-4465-847d-5de8c876cee9')]\n",
      "💡\u001b[92mLLM is Thinking !\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  RAG System (call_haali20w)\n",
      " Call ID: call_haali20w\n",
      "  Args:\n",
      "    query: Dogs againt Chats using llama3 model on Ollama server\n",
      "Tofv ndnfvn     dict_keys(['name', 'args', 'id', 'type'])\n",
      "⚙️\u001b[93m RAG System is Executing\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:01<00:00,  1.52s/it]\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/langchain_core/vectorstores/base.py:784: UserWarning: Relevance scores must be between 0 and 1, got [(Document(metadata={'content_type': 'text/html; charset=utf-8', 'description': 'This section contains introductions to key parts of LangChain.', 'id': '25', 'language': 'en', 'source': 'https://python.langchain.com/v0.2/docs/concepts/#langchain-expression-language-lcel', 'title': 'Conceptual guide | 🦜️🔗 LangChain'}, page_content='Please see the tool calling section for more information.For specifics on how to use chat models, see the relevant how-to guides here.Multimodality\\u200bSome chat models are multimodal, accepting images, audio and even video as inputs. These are still less common, meaning model providers haven\\'t standardized on the \"best\" way to define the API. Multimodal outputs are even less common. As such, we\\'ve kept our multimodal abstractions fairly light weight and plan to further solidify the multimodal APIs and interaction patterns as the field matures.In LangChain, most chat models that support multimodal inputs also accept those values in OpenAI\\'s content blocks format. So far this is restricted to image inputs. For models like Gemini which support video and other bytes input, the APIs also support'), -233.9645399418365), (Document(metadata={'content_type': 'text/html; charset=utf-8', 'description': 'This section contains introductions to key parts of LangChain.', 'id': '26', 'language': 'en', 'source': 'https://python.langchain.com/v0.2/docs/concepts/#langchain-expression-language-lcel', 'title': 'Conceptual guide | 🦜️🔗 LangChain'}, page_content='like Gemini which support video and other bytes input, the APIs also support the native, model-specific representations.For specifics on how to use multimodal models, see the relevant how-to guides here.For a full list of LangChain model providers with multimodal models, check out this table.LLMs\\u200bcautionPure text-in/text-out LLMs tend to be older or lower-level. Many popular models are best used as chat completion models,'), -236.37963932955734), (Document(metadata={'content_type': 'text/html; charset=utf-8', 'description': 'This section contains introductions to key parts of LangChain.', 'id': '23', 'language': 'en', 'source': 'https://python.langchain.com/v0.2/docs/concepts/#langchain-expression-language-lcel', 'title': 'Conceptual guide | 🦜️🔗 LangChain'}, page_content='To find all the parameters supported by a ChatModel head to the API reference for that model.infoTool Calling Some chat models have been fine-tuned for tool calling and provide a dedicated API for tool calling.'), -236.85526617782799)]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: RAG System\n",
      "\n",
      "Please see the tool calling section for more information.For specifics on how to use chat models, see the relevant how-to guides here.Multimodality​Some chat models are multimodal, accepting images, audio and even video as inputs. These are still less common, meaning model providers haven't standardized on the \"best\" way to define the API. Multimodal outputs are even less common. As such, we've kept our multimodal abstractions fairly light weight and plan to further solidify the multimodal APIs and interaction patterns as the field matures.In LangChain, most chat models that support multimodal inputs also accept those values in OpenAI's content blocks format. So far this is restricted to image inputs. For models like Gemini which support video and other bytes input, the APIs also support\n",
      "\n",
      "---\n",
      "\n",
      "like Gemini which support video and other bytes input, the APIs also support the native, model-specific representations.For specifics on how to use multimodal models, see the relevant how-to guides here.For a full list of LangChain model providers with multimodal models, check out this table.LLMs​cautionPure text-in/text-out LLMs tend to be older or lower-level. Many popular models are best used as chat completion models,\n",
      "\n",
      "---\n",
      "\n",
      "To find all the parameters supported by a ChatModel head to the API reference for that model.infoTool Calling Some chat models have been fine-tuned for tool calling and provide a dedicated API for tool calling.\n",
      "\u001b[94mState messages :\u001b[0m [SystemMessage(content='You are Code Assistent Bot have a strong Knowledge about Langchain exepression Language and you can use tools that can help you', id='f2303565-641f-4585-a472-60a53f06a893'), HumanMessage(content='hi!', id='2f301cc3-5d1b-4465-bf4b-e5c4a95af9bb'), AIMessage(content='Hello! How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 208, 'total_tokens': 218}, 'model_name': 'llama3-groq-tool-use:8b', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None}, id='run-12296008-71a5-46af-be54-eb5870d018c3-0', usage_metadata={'input_tokens': 208, 'output_tokens': 10, 'total_tokens': 218}), SystemMessage(content='You are Code Assistent Bot have a strong Knowledge about Langchain exepression Language and you can use tools that can help you', id='c9205bf3-6bff-4c7e-a132-7f5727a93cce'), HumanMessage(content='How can I use a prompt and model to create a chain in LCEL that returns raw ChatMessages?', id='ce42c607-750f-4b49-be75-b3e8689c8bc0'), AIMessage(content=\"To create a chain of prompts and models for generating raw Chat Messages using Langchain Expressions Language, you'll need to construct a query string. Could you provide me with the specifics of your prompt and desired output?\", response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 275, 'total_tokens': 319}, 'model_name': 'llama3-groq-tool-use:8b', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None}, id='run-e566ca92-7849-4d90-9d07-eafdc4f8f840-0', usage_metadata={'input_tokens': 275, 'output_tokens': 44, 'total_tokens': 319}), SystemMessage(content='You are Code Assistent Bot have a strong Knowledge about Langchain exepression Language and you can use tools that can help you', id='f696949a-bd55-4373-8beb-59825ffd7dfd'), HumanMessage(content='How can I use a prompt and model to create a chain in LCEL that returns raw ChatMessages?, Give me the Code', id='d5931ed2-6d1e-4080-99c5-3013a1bd12e9'), AIMessage(content=\"To assist you accurately, could you specify the exact prompt you wish to use and the model you'd like to leverage for generating these raw Chat Messages?\", response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 380, 'total_tokens': 411}, 'model_name': 'llama3-groq-tool-use:8b', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None}, id='run-c53c4a5d-73b5-4bf0-86f1-628397592d2c-0', usage_metadata={'input_tokens': 380, 'output_tokens': 31, 'total_tokens': 411}), SystemMessage(content='You are Code Assistent Bot have a strong Knowledge about Langchain exepression Language and you can use tools that can help you', id='7dfd83b5-76cf-41a3-98f3-b9cc7dd02e7b'), HumanMessage(content='How can I use a prompt and model to create a chain in LCEL that returns raw ChatMessages?, Give me the Code , The Prompt = Dogs aginst Chats, The Model is llama3 with Ollama server', id='d77997d8-449e-4465-847d-5de8c876cee9'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_haali20w', 'function': {'arguments': '{\"query\":\"Dogs againt Chats using llama3 model on Ollama server\"}', 'name': 'RAG System'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 492, 'total_tokens': 533}, 'model_name': 'llama3-groq-tool-use:8b', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None}, id='run-1f19968a-52d3-48a7-9192-efe35cce2cb7-0', tool_calls=[{'name': 'RAG System', 'args': {'query': 'Dogs againt Chats using llama3 model on Ollama server'}, 'id': 'call_haali20w', 'type': 'tool_call'}], usage_metadata={'input_tokens': 492, 'output_tokens': 41, 'total_tokens': 533}), ToolMessage(content='Please see the tool calling section for more information.For specifics on how to use chat models, see the relevant how-to guides here.Multimodality\\u200bSome chat models are multimodal, accepting images, audio and even video as inputs. These are still less common, meaning model providers haven\\'t standardized on the \"best\" way to define the API. Multimodal outputs are even less common. As such, we\\'ve kept our multimodal abstractions fairly light weight and plan to further solidify the multimodal APIs and interaction patterns as the field matures.In LangChain, most chat models that support multimodal inputs also accept those values in OpenAI\\'s content blocks format. So far this is restricted to image inputs. For models like Gemini which support video and other bytes input, the APIs also support\\n\\n---\\n\\nlike Gemini which support video and other bytes input, the APIs also support the native, model-specific representations.For specifics on how to use multimodal models, see the relevant how-to guides here.For a full list of LangChain model providers with multimodal models, check out this table.LLMs\\u200bcautionPure text-in/text-out LLMs tend to be older or lower-level. Many popular models are best used as chat completion models,\\n\\n---\\n\\nTo find all the parameters supported by a ChatModel head to the API reference for that model.infoTool Calling Some chat models have been fine-tuned for tool calling and provide a dedicated API for tool calling.', name='RAG System', id='65b86321-8f10-4265-b0a7-eaefc205cbdc', tool_call_id='call_haali20w')]\n",
      "💡\u001b[92mLLM is Thinking !\u001b[0m\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "   (call_m9z8azd8)\n",
      " Call ID: call_m9z8azd8\n",
      "  Args:\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"2\"}} \n",
    "# We configurate here the id of the State to load by the graph\n",
    "\n",
    "My_Quetion = \"What is my Name , and Where I study Now ?\"\n",
    "Messages = [\n",
    "    SystemMessage(content=\"You are Code Assistent Bot have a strong Knowledge about Langchain exepression Language and you can use tools that can help you\"),\n",
    "    HumanMessage(content=\"How can I use a prompt and model to create a chain in LCEL that returns raw ChatMessages?, Give me the Code , The Prompt = Dogs aginst Chats, The Model is llama3 with Ollama server\")\n",
    "]\n",
    "Input_Message = {\"messages\": Messages}\n",
    "\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(Input_Message, config, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are Code Assistent Bot have a strong Knowledge about Langchain exepression Language and you can use tools that can help you', id='f2303565-641f-4585-a472-60a53f06a893'),\n",
       " HumanMessage(content='hi!', id='2f301cc3-5d1b-4465-bf4b-e5c4a95af9bb'),\n",
       " AIMessage(content='Hello! How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 208, 'total_tokens': 218}, 'model_name': 'llama3-groq-tool-use:8b', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None}, id='run-12296008-71a5-46af-be54-eb5870d018c3-0', usage_metadata={'input_tokens': 208, 'output_tokens': 10, 'total_tokens': 218}),\n",
       " SystemMessage(content='You are Code Assistent Bot have a strong Knowledge about Langchain exepression Language and you can use tools that can help you', id='c9205bf3-6bff-4c7e-a132-7f5727a93cce'),\n",
       " HumanMessage(content='How can I use a prompt and model to create a chain in LCEL that returns raw ChatMessages?', id='ce42c607-750f-4b49-be75-b3e8689c8bc0'),\n",
       " AIMessage(content=\"To create a chain of prompts and models for generating raw Chat Messages using Langchain Expressions Language, you'll need to construct a query string. Could you provide me with the specifics of your prompt and desired output?\", response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 275, 'total_tokens': 319}, 'model_name': 'llama3-groq-tool-use:8b', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None}, id='run-e566ca92-7849-4d90-9d07-eafdc4f8f840-0', usage_metadata={'input_tokens': 275, 'output_tokens': 44, 'total_tokens': 319}),\n",
       " SystemMessage(content='You are Code Assistent Bot have a strong Knowledge about Langchain exepression Language and you can use tools that can help you', id='f696949a-bd55-4373-8beb-59825ffd7dfd'),\n",
       " HumanMessage(content='How can I use a prompt and model to create a chain in LCEL that returns raw ChatMessages?, Give me the Code', id='d5931ed2-6d1e-4080-99c5-3013a1bd12e9'),\n",
       " AIMessage(content=\"To assist you accurately, could you specify the exact prompt you wish to use and the model you'd like to leverage for generating these raw Chat Messages?\", response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 380, 'total_tokens': 411}, 'model_name': 'llama3-groq-tool-use:8b', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None}, id='run-c53c4a5d-73b5-4bf0-86f1-628397592d2c-0', usage_metadata={'input_tokens': 380, 'output_tokens': 31, 'total_tokens': 411}),\n",
       " SystemMessage(content='You are Code Assistent Bot have a strong Knowledge about Langchain exepression Language and you can use tools that can help you', id='7dfd83b5-76cf-41a3-98f3-b9cc7dd02e7b'),\n",
       " HumanMessage(content='How can I use a prompt and model to create a chain in LCEL that returns raw ChatMessages?, Give me the Code , The Prompt = Dogs aginst Chats, The Model is llama3 with Ollama server', id='d77997d8-449e-4465-847d-5de8c876cee9'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_haali20w', 'function': {'arguments': '{\"query\":\"Dogs againt Chats using llama3 model on Ollama server\"}', 'name': 'RAG System'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 492, 'total_tokens': 533}, 'model_name': 'llama3-groq-tool-use:8b', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None}, id='run-1f19968a-52d3-48a7-9192-efe35cce2cb7-0', tool_calls=[{'name': 'RAG System', 'args': {'query': 'Dogs againt Chats using llama3 model on Ollama server'}, 'id': 'call_haali20w', 'type': 'tool_call'}], usage_metadata={'input_tokens': 492, 'output_tokens': 41, 'total_tokens': 533}),\n",
       " ToolMessage(content='Please see the tool calling section for more information.For specifics on how to use chat models, see the relevant how-to guides here.Multimodality\\u200bSome chat models are multimodal, accepting images, audio and even video as inputs. These are still less common, meaning model providers haven\\'t standardized on the \"best\" way to define the API. Multimodal outputs are even less common. As such, we\\'ve kept our multimodal abstractions fairly light weight and plan to further solidify the multimodal APIs and interaction patterns as the field matures.In LangChain, most chat models that support multimodal inputs also accept those values in OpenAI\\'s content blocks format. So far this is restricted to image inputs. For models like Gemini which support video and other bytes input, the APIs also support\\n\\n---\\n\\nlike Gemini which support video and other bytes input, the APIs also support the native, model-specific representations.For specifics on how to use multimodal models, see the relevant how-to guides here.For a full list of LangChain model providers with multimodal models, check out this table.LLMs\\u200bcautionPure text-in/text-out LLMs tend to be older or lower-level. Many popular models are best used as chat completion models,\\n\\n---\\n\\nTo find all the parameters supported by a ChatModel head to the API reference for that model.infoTool Calling Some chat models have been fine-tuned for tool calling and provide a dedicated API for tool calling.', name='RAG System', id='65b86321-8f10-4265-b0a7-eaefc205cbdc', tool_call_id='call_haali20w'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_m9z8azd8', 'function': {'arguments': 'null', 'name': ''}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 100, 'prompt_tokens': 833, 'total_tokens': 933}, 'model_name': 'llama3-groq-tool-use:8b', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None}, id='run-209479c5-4fcf-4211-bf68-da99d58d7410-0', tool_calls=[{'name': '', 'args': {}, 'id': 'call_m9z8azd8', 'type': 'tool_call'}], usage_metadata={'input_tokens': 833, 'output_tokens': 100, 'total_tokens': 933})]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Graph_execution = graph.get_state(config)\n",
    "Graph_execution.values[\"messages\"]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
