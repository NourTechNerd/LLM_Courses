{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idea :\n",
    "\n",
    "- We will create Summaries for Text,Images,Tables we well use it for indexing,but while retriving we will retrive raw text,Image.\n",
    "- It's exactely same as Traditional RAG, but here the Retrievere can return mutltimodal content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extract data from the docs :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Texts with the summaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "Current_diractory = r\"C:\\Users\\hp\\Downloads\\LLM_Courses\\Pratiques\\RAG\\Mutltimodal_RAG\\MRAG with Langchain\"\n",
    "Rapport1_path = os.path.join(Current_diractory, \"data\", \"Rapport1.pdf\")\n",
    "Rapport2_path = os.path.join(Current_diractory, \"data\", \"Rapport2.pdf\")\n",
    "file_path = os.path.join(Current_diractory, \"data\", \"Transcription.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "\n",
    "def ExtractTextFromPDF(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "\n",
    "    with open(file_path, \"w\") as f:\n",
    "        f.write(text)\n",
    "    f.close()\n",
    "    print(f\"Transcription saved to {file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ExtractTextFromPDF(Rapport1_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chunking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def Chunking(text):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=2000,     \n",
    "        chunk_overlap=400)\n",
    "\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "chunks = Chunking(text)\n",
    "\n",
    "print(f\"Number of Chunks : {len(chunks)}\")\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i+1}: {len(chunk)}\\n\")\n",
    "    print(chunk + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chain for Text Summaries :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = \"AIzaSyCFFqwIYR4cUnyEPvHsQTs0rFbhYrzBvM0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI \n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\",api_key=  GOOGLE_API_KEY)  \n",
    "\n",
    "Text_summarizer_system_prompt = \"\"\"\n",
    "Vous etes un expert de generation des resumés\\n \n",
    "donant un text vous pouvez génerer un résumé informative contient tout les \n",
    "elemnets clés de text.\\n \n",
    "Ne pas ajouter voutre propres idés au connaissance  just apartir de text\\n\n",
    "Ne pas ajouter voutre avis a propos le text.\\n \n",
    "Il faut inclure tout information clés dans le voutre résumé comme :\n",
    "les noms des persones,les coins,des organizations,les references...\\n \n",
    "Ajouter un Titre Clair en haut de voutre résumé.\\n\n",
    "Repondre en Francais\"\"\"\n",
    "\n",
    "Text_summarizer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", Text_summarizer_system_prompt),\n",
    "        (\"human\", \"Le text a resumé ici :\\n {Text}\"),\n",
    "    ]\n",
    ")\n",
    "  \n",
    "Text_summarizer = Text_summarizer_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Texts_summaries(chunks):\n",
    "    Texts_summaries = []\n",
    "    for chunk in tqdm(chunks, desc=\"Generating chunks summaries\"):\n",
    "        chunk_summary = Text_summarizer.invoke({\"Text\":chunk}).content\n",
    "        Texts_summaries.append(chunk_summary)\n",
    "    return Texts_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Texts_summaries = Get_Texts_summaries(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chunks_Summaries = [{\"Text\": chunk, \"Summary\": summary} for chunk, summary in zip(chunks, Texts_summaries)]\n",
    "Chunks_Summaries[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Images Urls with the Summaries :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi, HfFolder\n",
    "import fitz\n",
    "\n",
    "HfFolder.save_token(\"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\")\n",
    "api = HfApi()\n",
    "repo_name = \"Noureddinesa/Images\"\n",
    "\n",
    "def Save_To_HuggingFace(image_bytes,name):\n",
    "    api.upload_file(\n",
    "            path_or_fileobj=image_bytes,\n",
    "            path_in_repo=f\"{name}.png\",\n",
    "            repo_id=repo_name\n",
    "        )\n",
    "    print(f\"Image {name} uploaded\")\n",
    "    image_url = f\"https://huggingface.co/{repo_name}/resolve/main/{name}.png\"\n",
    "    return image_url\n",
    "     \n",
    "\n",
    "def ExtractImagesFromPDF(pdf_path):\n",
    "    Images_urls = []\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc.load_page(page_num)\n",
    "            img_list = page.get_images(full=True)\n",
    "            for img_index, img in enumerate(img_list):\n",
    "                xref = img[0]\n",
    "                base_image = doc.extract_image(xref)\n",
    "                image_bytes = base_image[\"image\"]\n",
    "                image_name =  f\"image{page_num + 1}_{img_index}\"\n",
    "                image_url = Save_To_HuggingFace(image_bytes,image_name)\n",
    "                #image_extension = base_image[\"ext\"]\n",
    "                #image_path = os.path.join(Current_diractory,\"data\",\"Images\", f\"image{page_num + 1}_{img_index}.{image_extension}\")\n",
    "                Images_urls.append(image_url)\n",
    "                #print(f\"Image {image_path} saved\")\n",
    "    return Images_urls\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Images_urls = ExtractImagesFromPDF(Rapport1_path)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chain for Images summaries :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage,SystemMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vlm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\",api_key = GOOGLE_API_KEY)  \n",
    "\n",
    "Image_summarizer_system_prompt = \"\"\"\n",
    "Vous etes un expert dans la géneration de déscription d'une image donnée.\\n \n",
    "donant une Image vous étes capable de décrire exactemnet le contenu de l'Image\n",
    "et de quoi s'agit-il.\\n \n",
    "Ne pas ajouter voutre propres idés au connaissance  just apartir de l'image donnée\\n\n",
    "Ne pas ajouter voutre avis a propos le l'mage.\\n \n",
    "Il faut inclure tout information clés dans le voutre désciptions comme les\n",
    "chiffres les tites les statistics...\\n\n",
    "Donner un Titre clair a L'image en haut de votre déscription.\\n\n",
    "Repondre en Francais\"\"\"\n",
    "\n",
    "def Run_Image_summarizer(Image):\n",
    "    response = vlm.invoke(\n",
    "         [\n",
    "            SystemMessage(content=Image_summarizer_system_prompt),\n",
    "            HumanMessage(\n",
    "                content=[\n",
    "                    {\"type\": \"text\",\n",
    "                     \"text\":  f\"\"\"Image ici\n",
    "                        \"\"\"\n",
    "                    },\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": Image}},\n",
    "                ]\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    return response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Images_summaries(Images_urls):\n",
    "    Images_summaries = []\n",
    "    counter = 0\n",
    "    for image_url in tqdm(Images_urls, desc=\"Generating images summaries\"):\n",
    "        image_summary = Run_Image_summarizer(image_url)\n",
    "        Images_summaries.append(image_summary)\n",
    "        counter+=1\n",
    "        # Sleep Gemini so we not exceds the 15 RPM Limit of the API\n",
    "        if counter >= 10 :\n",
    "            print(\"Sleep for 1 min\")\n",
    "            time.sleep(60)\n",
    "            counter = 0\n",
    "            \n",
    "    return Images_summaries\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Images_summaries = Get_Images_summaries(Images_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Images_Summaries = [{\"ImageURL\": imageurl, \"Summary\": summary} for imageurl, summary in zip(Images_urls, Images_summaries)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build FAISS VectoreStore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n",
    "from langchain.schema import Document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "NVIDIA_API_KEY = \"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\"\n",
    "embeddings = NVIDIAEmbeddings(model= \"nvidia/nv-embed-v1\",nvidia_api_key = NVIDIA_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "for item in Chunks_Summaries:\n",
    "    documents.append(Document(\n",
    "        page_content=item[\"Summary\"],  \n",
    "        metadata={\"chunk\": item[\"Text\"]}\n",
    "    ))\n",
    "for item in Images_Summaries:\n",
    "    documents.append(Document(\n",
    "        page_content=item[\"Summary\"],   \n",
    "        metadata={\"image_url\": item[\"ImageURL\"]}\n",
    "    ))\n",
    "\n",
    "vector_store = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vector_store.similarity_search_with_score(\"Les resultast de Eco conception realisé par les etudiants\", k=2)\n",
    "for res, score in results:\n",
    "    print(f\"* [SIM={score:3f}] {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Images_Summaries[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "New",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
